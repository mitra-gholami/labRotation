{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:01.736784Z",
     "start_time": "2024-07-15T07:14:00.936753Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.load_results import *\n",
    "from utils.plot_helpers import *\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from utils.analysis_from_interaction import *\n",
    "from language_analysis_local import TopographicSimilarityConceptLevel, encode_target_concepts_for_topsim\n",
    "from egg.core.callbacks import Checkpoint, CheckpointSaver\n",
    "from egg import core\n",
    "from archs import Sender, Receiver\n",
    "import torch.nn as nn\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# For convenince and reproducibility, we set some EGG-level command line arguments here\n",
    "opts = core.init(params=['--random_seed=7', # will initialize numpy, torch, and python RNGs\n",
    "                         '--lr=1e-3',   # sets the learning rate for the selected optimizer \n",
    "                         '--batch_size=32',\n",
    "                         '--optimizer=adam'])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATH = 'results/(3,16)_game_size_10_vsf_3/context_unaware/0/final.tar'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:01.742168Z",
     "start_time": "2024-07-15T07:14:01.737939Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:01.754408Z",
     "start_time": "2024-07-15T07:14:01.742463Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('results/(3,16)_game_size_10_vsf_3/context_unaware/0/final.tar', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:01.846387Z",
     "start_time": "2024-07-15T07:14:01.842281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "odict_keys(['sender.sos_embedding', 'sender.agent.fc1.weight', 'sender.agent.fc1.bias', 'sender.agent.fc2.weight', 'sender.agent.fc2.bias', 'sender.agent.fc3.weight', 'sender.agent.fc3.bias', 'sender.hidden_to_output.weight', 'sender.hidden_to_output.bias', 'sender.embedding.weight', 'sender.embedding.bias', 'sender.cell.weight_ih', 'sender.cell.weight_hh', 'sender.cell.bias_ih', 'sender.cell.bias_hh', 'receiver.agent.fc1.weight', 'receiver.agent.fc1.bias', 'receiver.cell.weight_ih', 'receiver.cell.weight_hh', 'receiver.cell.bias_ih', 'receiver.cell.bias_hh', 'receiver.embedding.weight', 'receiver.embedding.bias'])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.model_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:02.869282Z",
     "start_time": "2024-07-15T07:14:02.858422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.8701,  0.0479, -0.1091,  ...,  0.0326,  0.2438, -0.3867],\n        [-0.3235, -0.1801, -0.4256,  ...,  0.0961,  0.0574,  0.1874],\n        [ 0.7095, -0.2960,  0.1394,  ..., -0.5463, -0.4298,  0.0175],\n        ...,\n        [-0.2111,  0.0888,  0.4646,  ...,  0.6277, -1.3281, -0.5050],\n        [ 0.0230, -0.5596, -0.0051,  ..., -0.3808,  0.4454, -0.0312],\n        [-0.1740, -0.8687,  0.0640,  ..., -0.1535, -0.3937,  0.5670]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.model_state_dict['sender.agent.fc1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "dimensions = [16, 16, 16]\n",
    "game_size = 10\n",
    "context_unaware = True\n",
    "vocab_size_factor = 3\n",
    "max_mess_len = None\n",
    "sender_cell = 'gru'\n",
    "temperature = 2.0\n",
    "receiver_cell = 'gru'\n",
    "learning_rate = 0.001\n",
    "device = 'cuda'\n",
    "path = ''\n",
    "load_dataset = 'dim(3,16).ds'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:03.795767Z",
     "start_time": "2024-07-15T07:14:03.784274Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def loss(_sender_input, _message, _receiver_input, receiver_output, labels, _aux_input):\n",
    "    \"\"\"\n",
    "    Loss needs to be defined for gumbel softmax relaxation.\n",
    "    For a discriminative game, accuracy is computed by comparing the index with highest score in Receiver\n",
    "    output (a distribution of unnormalized probabilities over target positions) and the corresponding \n",
    "    label read from input, indicating the ground-truth position of the target.\n",
    "    Adaptation to concept game with multiple targets after Mu & Goodman (2021) with BCEWithLogitsLoss\n",
    "        receiver_output: Tensor of shape [batch_size, n_objects]\n",
    "        labels: Tensor of shape [batch_size, n_objects]\n",
    "    \"\"\"\n",
    "    # after Mu & Goodman (2021):\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss = loss_fn(receiver_output, labels)\n",
    "    receiver_pred = (receiver_output > 0).float()\n",
    "    per_game_acc = (receiver_pred == labels).float().mean(1).cpu().numpy()  # all labels have to be predicted correctly\n",
    "    acc = per_game_acc.mean()\n",
    "    return loss, {'acc': acc}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:04.372327Z",
     "start_time": "2024-07-15T07:14:04.362924Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded from: data/dim(3,16).ds\n"
     ]
    }
   ],
   "source": [
    "data_set = torch.load(path + 'data/' + load_dataset)\n",
    "print('data loaded from: ' + 'data/' + load_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:14.350817Z",
     "start_time": "2024-07-15T07:14:04.904052Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train, val, test = data_set\n",
    "train = torch.utils.data.DataLoader(train, batch_size = opts.batch_size, shuffle=False)\n",
    "val = torch.utils.data.DataLoader(val, batch_size = opts.batch_size, shuffle=False)\n",
    "test = torch.utils.data.DataLoader(test, batch_size=opts.batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:14.354654Z",
     "start_time": "2024-07-15T07:14:14.351517Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "865"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test) # n batches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:14.357247Z",
     "start_time": "2024-07-15T07:14:14.353874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "sender = Sender(hidden_size, sum(dimensions), game_size, context_unaware)\n",
    "receiver = Receiver(sum(dimensions), hidden_size)\n",
    "\n",
    "minimum_vocab_size = dimensions[0] + 1  # plus one for 'any'\n",
    "vocab_size = minimum_vocab_size * vocab_size_factor + 1  # multiply by factor plus add one for eos-symbol\n",
    "\n",
    "# allow user to specify a maximum message length\n",
    "if max_mess_len:\n",
    "    max_len = max_mess_len\n",
    "# default: number of attributes\n",
    "else:\n",
    "    max_len = len(dimensions)\n",
    "\n",
    "sender = core.RnnSenderGS(sender,\n",
    "                          vocab_size,\n",
    "                          int(hidden_size / 2),\n",
    "                          hidden_size,\n",
    "                          cell=sender_cell,\n",
    "                          max_len=max_len,\n",
    "                          temperature=temperature)\n",
    "\n",
    "receiver = core.RnnReceiverGS(receiver,\n",
    "                              vocab_size,\n",
    "                              int(hidden_size / 2),\n",
    "                              hidden_size,\n",
    "                              cell=receiver_cell)\n",
    "\n",
    "game = core.SenderReceiverRnnGS(sender, receiver, loss)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "        {'params': game.sender.parameters(), 'lr': learning_rate},\n",
    "        {'params': game.receiver.parameters(), 'lr': learning_rate}\n",
    "    ])\n",
    "\n",
    "trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train, validation_data=val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:14.391881Z",
     "start_time": "2024-07-15T07:14:14.358985Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "game.load_state_dict(checkpoint.model_state_dict)\n",
    "optimizer.load_state_dict(checkpoint.optimizer_state_dict)\n",
    "epoch = checkpoint.epoch\n",
    "\n",
    "mean_loss, interaction = trainer.eval(data=test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:15.997017Z",
     "start_time": "2024-07-15T07:14:14.374187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2960352599620819"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:16.001592Z",
     "start_time": "2024-07-15T07:14:15.997735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9015)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction.aux['acc'].mean()\n",
    "# what's the baseline chance accuracy?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:16.005731Z",
     "start_time": "2024-07-15T07:14:16.000159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train, val, test = data_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:16.006524Z",
     "start_time": "2024-07-15T07:14:16.003275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [16], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;129;01min\u001B[39;00m train:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m objects \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m:\n\u001B[0;32m----> 6\u001B[0m         sampled_messages\u001B[38;5;241m.\u001B[39mappend(\u001B[43mgame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjects\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Projects/phdproject1/EGG/egg/core/gs_wrappers.py:334\u001B[0m, in \u001B[0;36mRnnSenderGS.forward\u001B[0;34m(self, x, aux_input)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, aux_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 334\u001B[0m     prev_hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maux_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    335\u001B[0m     prev_c \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros_like(prev_hidden)  \u001B[38;5;66;03m# only for LSTM\u001B[39;00m\n\u001B[1;32m    337\u001B[0m     e_t \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msos_embedding] \u001B[38;5;241m*\u001B[39m prev_hidden\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Projects/phdproject1/emergent-abstractions/archs.py:31\u001B[0m, in \u001B[0;36mSender.forward\u001B[0;34m(self, x, aux_input)\u001B[0m\n\u001B[1;32m     29\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     30\u001B[0m n_obj \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m---> 31\u001B[0m n_features \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     32\u001B[0m n_targets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(n_obj \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# embed target objects:\u001B[39;00m\n",
      "\u001B[0;31mIndexError\u001B[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "game.eval()\n",
    "sampled_messages = []\n",
    "\n",
    "for iter in train:\n",
    "    for objects in iter:\n",
    "        sampled_messages.append(game.sender(objects))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T07:14:16.157833Z",
     "start_time": "2024-07-15T07:14:16.006239Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
