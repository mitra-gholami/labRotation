{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T15:29:07.572926Z",
     "start_time": "2025-03-22T15:29:07.571733Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils.analysis_from_interaction import *\n",
    "from egg.core.language_analysis import Disent\n",
    "from language_analysis_local import TopographicSimilarityConceptLevel, encode_target_concepts_for_topsim\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate metrics from stored interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:59:14.931675Z",
     "start_time": "2025-01-13T11:59:14.858017Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ('(3,4)', '(3,8)', '(3,16)', '(4,4)', '(4,8)', '(5,4)')\n",
    "n_attributes = (3, 3, 3, 4, 4, 5)\n",
    "n_values = (4, 8, 16, 4, 8, 4)\n",
    "epochs = 300\n",
    "n_runs = 5\n",
    "paths = ['results/' + d + '_game_size_10_vsf_0/' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T12:40:28.264213Z",
     "start_time": "2025-01-08T12:40:28.224174Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = ('(3,4)', '(3,8)', '(4,4)')\n",
    "n_attributes = (3, 3, 4)\n",
    "n_values = (4, 8, 4)\n",
    "epochs = 0\n",
    "n_runs = 5\n",
    "paths = ['results/' + d + '_game_size_10_vsf_0/' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:42:27.172420Z",
     "start_time": "2025-01-14T14:42:26.989278Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = ('(3,4)', )\n",
    "n_attributes = (3, )\n",
    "n_values = (4, )\n",
    "epochs = 10\n",
    "n_runs = 5\n",
    "paths = ['results/' + d + '_game_size_10_vsf_3/' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/3dshapes/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_feat_rep_game_size_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(game_size) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_vsf_3/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d, dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(datasets):\n\u001b[1;32m---> 10\u001b[0m     vs_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     11\u001b[0m     vocab_size \u001b[38;5;241m=\u001b[39m (n_values[d] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m vs_factor \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "game_size = 10\n",
    "datasets = ('shapes3d', )\n",
    "n_attributes = (3,)\n",
    "n_values = (4, )\n",
    "n_runs = 4\n",
    "epochs = 300\n",
    "\n",
    "paths = ['results/3dshapes/'+ d +'_feat_rep_game_size_' + str(game_size) + '_vsf_3/' for d in datasets]\n",
    "for d, dim in enumerate(datasets):\n",
    "    vs_factor = int(paths[-2])\n",
    "    vocab_sizes = (n_values[d] + 1) * vs_factor + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T10:34:46.953898Z",
     "start_time": "2025-03-25T10:34:46.918810Z"
    }
   },
   "outputs": [],
   "source": [
    "context_unaware = False # whether original or context_unaware simulations are evaluated\n",
    "zero_shot = True # whether zero-shot simulations are evaluated\n",
    "zero_shot_test = 'specific' # 'generic' or 'specific'\n",
    "test_interactions = False # whether scores should be calculated on test interactions\n",
    "test_mode = 'test' # 'test' or 'test_fine' or 'test_sampled_unscaled' or 'test_load_train'\n",
    "length_cost = False # whether length_cost was applied; length cost runs have been run with early stopping\n",
    "early_stopping = False # only with length cost and sampled context\n",
    "rsa = False \n",
    "rsa_test = 'testtrain'\n",
    "sampled_context = False\n",
    "shapes3d = True\n",
    "setting = \"\"\n",
    "hierarchical = False\n",
    "shared_context = False\n",
    "\n",
    "if length_cost:\n",
    "    setting = setting + 'length_cost/'\n",
    "    if not context_unaware:\n",
    "        setting = setting + 'context_aware'\n",
    "if context_unaware:\n",
    "    setting = setting + 'context_unaware'\n",
    "else:\n",
    "    if not length_cost:\n",
    "        setting = setting + 'standard'\n",
    "if hierarchical:\n",
    "    setting = setting + '/hierarchical'\n",
    "if shared_context:\n",
    "    setting = setting + '/shared_context'\n",
    "if zero_shot:\n",
    "    setting = setting + '/zero_shot/' + zero_shot_test\n",
    "elif sampled_context:\n",
    "    setting = setting + '/sampled_context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:42:32.677339Z",
     "start_time": "2025-01-14T14:42:32.531744Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get n_epochs if early stopping\n",
    "# debug this for 3dshapes should be able to get rid of rid clauses\n",
    "if early_stopping:\n",
    "    \n",
    "    n_epochs_all_data = []\n",
    "    for d in range(len(datasets)):\n",
    "        \n",
    "        n_epochs = []\n",
    "        \n",
    "        for run in range(n_runs):\n",
    "            \n",
    "            path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "            \n",
    "            with open(os.path.join(path_to_run, 'loss_and_metrics.pkl'), 'rb') as input_file:\n",
    "                data = pickle.load(input_file)\n",
    "                final_epoch = max(data['loss_train'].keys())\n",
    "                n_epochs.append(final_epoch)\n",
    "                \n",
    "        n_epochs_all_data.append(n_epochs)\n",
    "        \n",
    "else:\n",
    "    n_epochs_all_data = []\n",
    "    for d in range(len(datasets)):\n",
    "        n_epochs = []\n",
    "        \n",
    "        for run in range(n_runs):\n",
    "            n_epochs.append(epochs)\n",
    "                \n",
    "        n_epochs_all_data.append(n_epochs)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entropy scores: MI, effectiveness, efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:19:07.400715Z",
     "start_time": "2025-03-24T10:18:45.265181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_17644\\536623715.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3/standard/zero_shot/specific/0/interactions/test/epoch_0/interaction_gpu0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     path_to_interaction \u001b[38;5;241m=\u001b[39m (path_to_run \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteractions/rsa_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m rsa_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/epoch_0/interaction_gpu0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m interaction \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_interaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m attributes \u001b[38;5;241m=\u001b[39m n_attributes[d]\n\u001b[0;32m     19\u001b[0m values \u001b[38;5;241m=\u001b[39m n_values[d]\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3/standard/zero_shot/specific/0/interactions/test/epoch_0/interaction_gpu0'"
     ]
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(0, n_runs):\n",
    "\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "            else:\n",
    "                path_to_interaction = (path_to_run + 'interactions/' + test_mode + '/epoch_0/interaction_gpu0')\n",
    "        else:\n",
    "            path_to_interaction = (path_to_run + 'interactions/rsa_' + rsa_test + '/epoch_0/interaction_gpu0')\n",
    "\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        is_gumbel = True \n",
    "        scores = information_scores(interaction, attributes, values, normalizer=\"arithmetic\", is_gumbel=is_gumbel, trim_eos=True, max_mess_len=21)   \n",
    "    \n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                pickle.dump(scores, open(path_to_run + 'entropy_scores.pkl', 'wb'))\n",
    "            else:\n",
    "                pickle.dump(scores, open(path_to_run + 'entropy_scores_' + test_mode + '.pkl', 'wb'))\n",
    "        else:\n",
    "            pickle.dump(scores, open(path_to_run + 'entropy_scores_rsa_' + rsa_test + '.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  message length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:19:24.840445Z",
     "start_time": "2025-03-24T10:19:07.402641Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_17644\\3823791230.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/(3,4)_game_size_10_vsf_3/standard/zero_shot/specific/0/interactions/train/epoch_10/interaction_gpu0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     path_to_interaction \u001b[38;5;241m=\u001b[39m (path_to_run \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteractions/rsa_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m rsa_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/epoch_0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/interaction_gpu0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m interaction \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_interaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m attributes \u001b[38;5;241m=\u001b[39m n_attributes[d]\n\u001b[0;32m     19\u001b[0m values \u001b[38;5;241m=\u001b[39m n_values[d]\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/(3,4)_game_size_10_vsf_3/standard/zero_shot/specific/0/interactions/train/epoch_10/interaction_gpu0'"
     ]
    }
   ],
   "source": [
    "# we evaluated message length per hierarchy level after training but \n",
    "# you can also use the HierarchicalMessageLength callback and store the results \n",
    "\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(0, n_runs): \n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        if not rsa:\n",
    "            path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        else:\n",
    "            path_to_interaction = (path_to_run + 'interactions/rsa_' + rsa_test + '/epoch_0' + '/interaction_gpu0')\n",
    "            \n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        ml, ml_concept = message_length_per_hierarchy_level(interaction, attributes)\n",
    "        ml_context, ml_fine_context, ml_coarse_context = message_length_per_context_condition(interaction, attributes)\n",
    "        scores = {'ml_over_context': ml_context, 'ml_fine_context': ml_fine_context, 'ml_coarse_context': ml_coarse_context}\n",
    "        \n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                pickle.dump(ml, open(path_to_run + 'message_length.pkl', 'wb'))\n",
    "                pickle.dump(ml_concept, open(path_to_run + 'message_length_hierarchical.pkl', 'wb'))\n",
    "                pickle.dump(scores, open(path_to_run + 'message_length_over_context.pkl', 'wb'))\n",
    "            else:\n",
    "                pickle.dump(ml, open(path_to_run + 'message_length_' + test_mode + '.pkl', 'wb'))\n",
    "                pickle.dump(ml_concept, open(path_to_run + 'message_length_hierarchical_' + test_mode + '.pkl', 'wb'))\n",
    "                pickle.dump(scores, open(path_to_run + 'message_length_over_context_' + test_mode + '.pkl', 'wb'))            \n",
    "        else:\n",
    "            pickle.dump(ml, open(path_to_run + 'message_length_rsa_' + rsa_test + '.pkl', 'wb'))\n",
    "            pickle.dump(ml_concept, open(path_to_run + 'message_length_hierarchical_rsa_' + rsa_test + '.pkl', 'wb'))\n",
    "            pickle.dump(scores, open(path_to_run + 'message_length_over_context_rsa_' + rsa_test + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## lexicon properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T10:35:12.383127Z",
     "start_time": "2025-03-25T10:34:50.840371Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes3d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_17644\\1416133678.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction)\n",
      "c:\\Users\\Isabella\\Desktop\\HiWi\\emergent-abstractions\\utils\\analysis_from_interaction.py:957: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lex_info = np.sum(informativeness) / len(informativeness)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lexicon informativeness': nan, 'lexicon size': 810, 'number of concepts': 810}\n",
      "{'lexicon informativeness': nan, 'lexicon size': 810, 'number of concepts': 810}\n",
      "{'lexicon informativeness': nan, 'lexicon size': 810, 'number of concepts': 810}\n",
      "{'lexicon informativeness': nan, 'lexicon size': 810, 'number of concepts': 810}\n"
     ]
    }
   ],
   "source": [
    "distance = 'manhattan' # 'manhattan' or 'euclidean'\n",
    "for d in range(len(datasets)):\n",
    "    print(datasets[d])\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(n_runs): \n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "            else:\n",
    "                path_to_interaction = (path_to_run + 'interactions/' + test_mode + '/epoch_0/interaction_gpu0')\n",
    "        else:\n",
    "            path_to_interaction = (path_to_run + 'interactions/rsa_' + rsa_test + '/epoch_0/interaction_gpu0')\n",
    "            \n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        lex_info, unique_messages, num_concepts = informativeness_score(interaction, distance=distance)\n",
    "        scores = {'lexicon informativeness': lex_info, 'lexicon size': unique_messages, 'number of concepts': num_concepts}\n",
    "        print(scores)\n",
    "\n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                pickle.dump(scores, open(path_to_run + 'lexicon_properties_' + distance + '.pkl', 'wb'))\n",
    "            else:\n",
    "                pickle.dump(scores, open(path_to_run + 'lexicon_properties_' + distance + '_' + test_mode  + '.pkl', 'wb'))\n",
    "        else:\n",
    "            pickle.dump(scores, open(path_to_run + 'lexicon_properties_' + distance + '_rsa_' + rsa_test + '.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  symbol redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:57:13.478625Z",
     "start_time": "2025-03-20T13:57:12.779556Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_sizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m attributes \u001b[38;5;241m=\u001b[39m n_attributes[d]\n\u001b[0;32m      6\u001b[0m values \u001b[38;5;241m=\u001b[39m n_values[d]\n\u001b[1;32m----> 7\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[43mvocab_sizes\u001b[49m[d]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs): \n\u001b[0;32m     11\u001b[0m     path_to_run \u001b[38;5;241m=\u001b[39m paths[d] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(setting) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(run) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_sizes' is not defined"
     ]
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    attributes = n_attributes[d]\n",
    "    values = n_values[d]\n",
    "    vocab_size = vocab_sizes[d]\n",
    "    \n",
    "    for run in range(n_runs): \n",
    "                \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "            else:\n",
    "                path_to_interaction = (path_to_run + 'interactions/' + test_mode + '/epoch_0/interaction_gpu0')\n",
    "        else:\n",
    "            path_to_interaction = (path_to_run + 'interactions/rsa_' + rsa_test + '/epoch_0/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "        redundancy, MI = symbol_frequency(interaction, attributes, values, vocab_size)\n",
    "        \n",
    "        scores = {'symbol_redundancy': redundancy, 'MI_symbol-attribute_value': MI}\n",
    "        \n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                pickle.dump(scores, open(path_to_run + 'symbol_redundancy.pkl', 'wb'))\n",
    "            else:\n",
    "                pickle.dump(scores, open(path_to_run + 'symbol_redundancy_' + test_mode + '.pkl', 'wb'))\n",
    "        else:\n",
    "            pickle.dump(scores, open(path_to_run + 'symbol_redundancy_rsa_' + rsa_test + '.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  compositionality scores: topsim, posdis, bosdis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### topsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T15:25:58.281682Z",
     "start_time": "2025-01-06T15:25:58.219778Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shapes3d run 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_17644\\563107622.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... topsim computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_17644\\563107622.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... topsim computed\n",
      "{'topsim_train': 0.2999318219347991, 'topsim_val': 0.30337765173278197}\n",
      "dataset shapes3d run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.332182680606627, 'topsim_val': 0.28940097610123355}\n",
      "dataset shapes3d run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.3419838787976565, 'topsim_val': 0.3634248580844698}\n",
      "dataset shapes3d run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.27551516347040667, 'topsim_val': 0.26038452971704046}\n"
     ]
    }
   ],
   "source": [
    "# topsim for train and validation\n",
    "# although topsim values are stored throughout training if callbacks are verbose, we reevaluate the\n",
    "# final topsim scores with more data points \n",
    "# not yet implemented for rsa\n",
    "\n",
    "samples = 5000 # maybe shuffle from these because otherwise I just take the first 5,000 (which might not be the best)\n",
    "for d, dataset in enumerate(datasets):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    dim = [n_values[d]]*n_attributes[d]\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        print(\"dataset\", dataset, \"run\", run)\n",
    "        \n",
    "        topsim_final = {}\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        \n",
    "        TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "        \n",
    "        for mode in ['train', 'val']:\n",
    "\n",
    "            if mode == 'train':\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "            elif mode == 'val':\n",
    "                interaction = torch.load(path_to_interaction_val)\n",
    "                  \n",
    "            messages = interaction.message.argmax(dim=-1)\n",
    "            sender_input = interaction.sender_input\n",
    "            n_targets = int(sender_input.shape[1]/2)\n",
    "            # get target objects and fixed vectors to re-construct concepts\n",
    "            target_objects = sender_input[:, :n_targets]\n",
    "            target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "            # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "            (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "            # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "            objects = objects + 1\n",
    "            concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "            specific_idx = np.where(np.sum(fixed, axis=1)==n_attributes[d])[0]\n",
    "            messages_specific = messages[specific_idx]\n",
    "            concepts_specific = concepts[specific_idx]\n",
    "            \n",
    "            generic_idx = np.where(np.sum(fixed, axis=1)==1)[0]\n",
    "            messages_generic = messages[generic_idx]\n",
    "            concepts_generic = concepts[generic_idx]\n",
    "\n",
    "            messages = [msg.tolist() for msg in messages]\n",
    "            messages_specific = [msg.tolist() for msg in messages_specific]\n",
    "            messages_generic = [msg.tolist() for msg in messages_generic]\n",
    "\n",
    "            encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[0:samples], messages[0:samples]) # default: hausdorff distance\n",
    "            \n",
    "            if not zero_shot:\n",
    "                topsim_specific = TOPSIM.compute_topsim(concepts_specific[0:samples], messages_specific[0:samples], \n",
    "                                                            meaning_distance_fn=\"edit\")\n",
    "                \n",
    "                topsim_generic = TOPSIM.compute_topsim(concepts_generic[0:samples], messages_generic[0:samples],\n",
    "                                                       meaning_distance_fn=\"edit\")\n",
    "\n",
    "            print('... topsim computed')\n",
    "\n",
    "            topsim_final['topsim_' + mode] = topsim\n",
    "            if not zero_shot:\n",
    "                topsim_final['topsim_specific_' + mode] = topsim_specific\n",
    "                topsim_final['topsim_generic_' + mode] = topsim_generic\n",
    "        \n",
    "        pickle.dump(topsim_final, open(path_to_run +  \"topsim_final.pkl\", \"wb\" ) )\n",
    "        print(topsim_final)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T10:21:03.603562Z",
     "start_time": "2024-12-19T10:21:03.427678Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shapes3d run 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_17644\\2581837213.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction_test)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3/standard/zero_shot/specific/0/interactions/test/epoch_0/interaction_gpu0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m path_to_interaction_test \u001b[38;5;241m=\u001b[39m (path_to_run \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteractions/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m test_mode \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/epoch_0/interaction_gpu0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m TOPSIM \u001b[38;5;241m=\u001b[39m TopographicSimilarityConceptLevel(dim, is_gumbel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 22\u001b[0m interaction \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_interaction_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m messages \u001b[38;5;241m=\u001b[39m interaction\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m sender_input \u001b[38;5;241m=\u001b[39m interaction\u001b[38;5;241m.\u001b[39msender_input\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\miniconda3\\envs\\emergab\\lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3/standard/zero_shot/specific/0/interactions/test/epoch_0/interaction_gpu0'"
     ]
    }
   ],
   "source": [
    "# topsim for test interactions\n",
    "zero_shot_test_ds = 'test_sampled_unscaled'\n",
    "if test_interactions:\n",
    "\n",
    "    samples = 5000 \n",
    "    for d, dataset in enumerate(datasets):\n",
    "        \n",
    "        n_epochs = n_epochs_all_data[d]\n",
    "        \n",
    "        dim = [n_values[d]]*n_attributes[d]\n",
    "        \n",
    "        for run in range(n_runs):\n",
    "            print(\"dataset\", dataset, \"run\", run)\n",
    "            \n",
    "            topsim_final = {}\n",
    "            path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "            mode = 'test'\n",
    "            path_to_interaction_test = (path_to_run + 'interactions/' + test_mode + '/epoch_0/interaction_gpu0')\n",
    "            \n",
    "            TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "            \n",
    "            interaction = torch.load(path_to_interaction_test)\n",
    "                      \n",
    "            messages = interaction.message.argmax(dim=-1)\n",
    "            sender_input = interaction.sender_input\n",
    "            n_targets = int(sender_input.shape[1]/2)\n",
    "            # get target objects and fixed vectors to re-construct concepts\n",
    "            target_objects = sender_input[:, :n_targets]\n",
    "            target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "            # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "            (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "            # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "            objects = objects + 1\n",
    "            concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "\n",
    "            messages = [msg.tolist() for msg in messages]\n",
    "\n",
    "            encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[0:samples], messages[0:samples])  \n",
    "\n",
    "            print('... topsim computed')\n",
    "\n",
    "            topsim_final['topsim_' + mode] = topsim\n",
    "    \n",
    "            pickle.dump(topsim_final, open(path_to_run +  \"topsim_final_\" + zero_shot_test_ds + \".pkl\", \"wb\" ) )\n",
    "            print(topsim_final)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Topsim over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T10:28:03.835447Z",
     "start_time": "2024-12-19T10:21:03.433212Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shapes3d run 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_17644\\1213916987.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction_train)\n",
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_17644\\1213916987.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shapes3d run 1\n",
      "dataset shapes3d run 2\n",
      "dataset shapes3d run 3\n"
     ]
    }
   ],
   "source": [
    "for d, dataset in enumerate(datasets):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        print(\"dataset\", dataset, \"run\", run)\n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        \n",
    "        for mode in ['train', 'val']:\n",
    "\n",
    "            if mode == 'train':\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "            elif mode == 'val':\n",
    "                interaction = torch.load(path_to_interaction_val)\n",
    "\n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        sender_input = interaction.sender_input\n",
    "        messages = [msg.tolist() for msg in messages]\n",
    "        encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "        dim = [n_values[0]] * n_attributes[0]\n",
    "        TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "        \n",
    "        samples = 5000\n",
    "        num_batches = len(messages) // samples + (len(messages) % samples > 0)\n",
    "        topsim_over_time = []\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            messages_batch = messages[i * samples:(i + 1) * samples]\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[i * samples:(i + 1) * samples], messages_batch)\n",
    "            topsim_over_time.append(topsim)\n",
    "            \n",
    "        pickle.dump(topsim_over_time, open(path_to_run +  \"topsim_over_time.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Posdis and Bosdis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T10:28:17.855966Z",
     "start_time": "2024-12-19T10:28:03.858483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set [4, 4, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_12676\\758300035.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'posdis_specific': 0.059139434248209, 'bosdis_specific': 0.025298602879047394, 'posdis_generic': 0.018802281469106674, 'bosdis_generic': 0.021713269874453545, 'posdis': 0.03365752846002579, 'bosdis': 0.017308223992586136}\n",
      "{'posdis_specific': 0.05834566429257393, 'bosdis_specific': 0.024831948801875114, 'posdis_generic': 0.03968323394656181, 'bosdis_generic': 0.025236455723643303, 'posdis': 0.03451243415474892, 'bosdis': 0.014397152699530125}\n",
      "{'posdis_specific': 0.03193020820617676, 'bosdis_specific': 0.032489385455846786, 'posdis_generic': 0.013751846738159657, 'bosdis_generic': 0.034938327968120575, 'posdis': 0.030376359820365906, 'bosdis': 0.018122123554348946}\n",
      "{'posdis_specific': 0.01606089435517788, 'bosdis_specific': 0.024671068415045738, 'posdis_generic': 0.0031657980289310217, 'bosdis_generic': 0.014459517784416676, 'posdis': 0.02509269118309021, 'bosdis': 0.011552517302334309}\n",
      "{'posdis_specific': 0.05291163921356201, 'bosdis_specific': 0.041545651853084564, 'posdis_generic': 0.019224321469664574, 'bosdis_generic': 0.03048313967883587, 'posdis': 0.032049793750047684, 'bosdis': 0.011989608407020569}\n"
     ]
    }
   ],
   "source": [
    "# use Disent callback from egg\n",
    "\n",
    "for d in range(len(datasets)): \n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    path = paths[d]\n",
    "    dim = [n_values[d]] * n_attributes[d]\n",
    "    n_features = n_attributes[d] * n_values[d]\n",
    "    vs_factor = int(path[-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    \n",
    "    print(\"data set\", dim)\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        \n",
    "        posdis_bosdis = {}\n",
    "    \n",
    "        path_to_run = paths[d] + '/' + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction_train)\n",
    "        \n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        sender_input = interaction.sender_input\n",
    "        n_targets = int(sender_input.shape[1]/2)\n",
    "        # get target objects and fixed vectors to re-construct concepts\n",
    "        target_objects = sender_input[:, :n_targets]\n",
    "        target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "        # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "        (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "        # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "        objects = objects + 1\n",
    "        concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "\n",
    "        # concrete/specific concepts: where all attributes are fixed\n",
    "        concepts_specific = torch.tensor(\n",
    "            objects[torch.sum(torch.from_numpy(fixed), dim=1) == n_attributes[d]])\n",
    "        messages_specific = messages[torch.sum(torch.from_numpy(fixed), dim=1) == n_attributes[d]]\n",
    "\n",
    "        # generic concepts: where only one attribute is fixed\n",
    "        concepts_generic = torch.tensor(\n",
    "            objects[torch.sum(torch.from_numpy(fixed), dim=1) == 1])\n",
    "        messages_generic = messages[torch.sum(torch.from_numpy(fixed), dim=1) == 1]\n",
    "        \n",
    "        posdis_specific = Disent.posdis(concepts_specific, messages_specific)\n",
    "        bosdis_specific = Disent.bosdis(concepts_specific, messages_specific, vocab_size)\n",
    "\n",
    "        posdis_generic = Disent.posdis(concepts_generic, messages_generic)\n",
    "        bosdis_generic = Disent.bosdis(concepts_generic, messages_generic, vocab_size)\n",
    "        \n",
    "        posdis = Disent.posdis(torch.from_numpy(objects), messages)\n",
    "        bosdis = Disent.bosdis(torch.from_numpy(objects), messages, vocab_size)\n",
    "        \n",
    "        posdis_bosdis['posdis_specific'] = posdis_specific\n",
    "        posdis_bosdis['bosdis_specific'] = bosdis_specific\n",
    "        posdis_bosdis['posdis_generic'] = posdis_generic\n",
    "        posdis_bosdis['bosdis_generic'] = bosdis_generic\n",
    "        posdis_bosdis['posdis'] = posdis\n",
    "        posdis_bosdis['bosdis'] = bosdis\n",
    "\n",
    "        print(posdis_bosdis)\n",
    "    \n",
    "        pickle.dump(posdis_bosdis, open(path_to_run + \"posdis_bosdis.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Posdis and bosdis concept x context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T10:28:18.267399Z",
     "start_time": "2024-12-19T10:28:17.857184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_12676\\2243785300.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction)\n"
     ]
    }
   ],
   "source": [
    "# bosdis concept x context\n",
    "from utils.analysis_from_interaction import bosdis\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "\n",
    "        path_to_run = paths[d] + '/' + str(setting) +'/' + str(run) + '/' \n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = bosdis(interaction, attributes, values, vocab_size)\n",
    "\n",
    "        pickle.dump(scores, open(path_to_run + 'bosdis_scores.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T10:28:25.205036Z",
     "start_time": "2024-12-19T10:28:18.268941Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3//standard/zero_shot/generic/0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_12676\\359269487.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3//standard/zero_shot/generic/1/\n",
      "results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3//standard/zero_shot/generic/2/\n",
      "results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3//standard/zero_shot/generic/3/\n",
      "results/3dshapes/shapes3d_feat_rep_game_size_10_vsf_3//standard/zero_shot/generic/4/\n"
     ]
    }
   ],
   "source": [
    "# posdis concept x context\n",
    "from utils.analysis_from_interaction import posdis\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        path_to_run = paths[d] + '/' + str(setting) + '/' + str(run) + '/'\n",
    "        print(path_to_run)\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        #print(path_to_interaction)\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = posdis(interaction, attributes, values, vocab_size)\n",
    "\n",
    "        pickle.dump(scores, open(path_to_run + 'posdis_scores.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## co-occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabella\\AppData\\Local\\Temp\\ipykernel_328\\2009805359.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  interaction = torch.load(path_to_interaction)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m attributes \u001b[38;5;241m=\u001b[39m n_attributes[d]\n\u001b[0;32m     14\u001b[0m values \u001b[38;5;241m=\u001b[39m n_values[d]\n\u001b[1;32m---> 16\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcooccurrence_per_hierarchy_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvs_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores)\n\u001b[0;32m     20\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(scores, \u001b[38;5;28mopen\u001b[39m(path_to_run \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_cooccurrence.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Isabella\\Desktop\\HiWi\\emergent-abstractions\\utils\\analysis_from_interaction.py:577\u001b[0m, in \u001b[0;36mcooccurrence_per_hierarchy_level\u001b[1;34m(interaction, n_attributes, n_values, vs_factor, is_gumbel, trim_eos)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    576\u001b[0m         relevance \u001b[38;5;241m=\u001b[39m relevance_vectors[i]\n\u001b[1;32m--> 577\u001b[0m         cooccurrence[s, \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrelevance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(m)\u001b[38;5;241m.\u001b[39mcount(s)\n\u001b[0;32m    579\u001b[0m cooccurrence \u001b[38;5;241m=\u001b[39m cooccurrence[\u001b[38;5;241m1\u001b[39m:, :]  \u001b[38;5;66;03m# remove eos symbol\u001b[39;00m\n\u001b[0;32m    580\u001b[0m split_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39msum(sender_input[:, \u001b[38;5;241m-\u001b[39mn_attributes:], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_attributes)])\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# Not yet implemented:\n",
    "\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    vs_factor = int(paths[d][-2])\n",
    "    \n",
    "    for run in range(n_runs): \n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        \n",
    "        scores = cooccurrence_per_hierarchy_level(interaction, attributes, values, vs_factor)\n",
    "\n",
    "        print(scores)\n",
    "        \n",
    "        pickle.dump(scores, open(path_to_run + 'normalized_cooccurrence.pkl', 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
